<!DOCTYPE  html>
<html>
  <head>
    <meta charset="utf-8">
    
    <title>doc</title>
    <style>
      /*github.com style (c) Vasily Polovnyov <vast@whiteants.net>*/
      pre code {
        display: block; padding: 0.5em;
        color: #333;
        background: #f8f8ff
      }
      pre .comment,
      pre .template_comment,
      pre .diff .header,
      pre .javadoc {
        color: #998;
        font-style: italic
      }
      pre .keyword,
      pre .css .rule .keyword,
      pre .winutils,
      pre .javascript .title,
      pre .nginx .title,
      pre .subst,
      pre .request,
      pre .status {
        color: #333;
        font-weight: bold
      }
      pre .number,
      pre .hexcolor,
      pre .ruby .constant {
        color: #099;
      }
      pre .string,
      pre .tag .value,
      pre .phpdoc,
      pre .tex .formula {
        color: #d14
      }
      pre .title,
      pre .id {
        color: #900;
        font-weight: bold
      }
      pre .javascript .title,
      pre .lisp .title,
      pre .clojure .title,
      pre .subst {
        font-weight: normal
      }
      pre .class .title,
      pre .haskell .type,
      pre .vhdl .literal,
      pre .tex .command {
        color: #458;
        font-weight: bold
      }
      pre .tag,
      pre .tag .title,
      pre .rules .property,
      pre .django .tag .keyword {
        color: #000080;
        font-weight: normal
      }
      pre .attribute,
      pre .variable,
      pre .lisp .body {
        color: #008080
      }
      pre .regexp {
        color: #009926
      }
      pre .class {
        color: #458;
        font-weight: bold
      }
      pre .symbol,
      pre .ruby .symbol .string,
      pre .lisp .keyword,
      pre .tex .special,
      pre .prompt {
        color: #990073
      }
      pre .built_in,
      pre .lisp .title,
      pre .clojure .built_in {
        color: #0086b3
      }
      pre .preprocessor,
      pre .pi,
      pre .doctype,
      pre .shebang,
      pre .cdata {
        color: #999;
        font-weight: bold
      }
      pre .deletion {
        background: #fdd
      }
      pre .addition {
        background: #dfd
      }
      pre .diff .change {
        background: #0086b3
      }
      pre .chunk {
        color: #aaa
      }
    </style>
  </head>
  <body>  
    <h1 id="title">Title</h1>
<h2 id="by-alasdair-smith">by Alasdair Smith</h2>
<p>Submitted in partial fulfilment of the requirements for the award of degree of Your Degree of the University of Portsmouth</p>
<p>April 2014</p>
<h3 id="copyright">Copyright</h3>
<p>Copyright &copy; Alasdair Smith. All rights reserved.
The copyright of this thesis rests with the Author. Copies (by any means) either in full, or of extracts, may not be made without prior written consent from the Author.</p>
<h3 id="preface">Preface</h3>
<p>If you have people to thank, do so on this page, otherwise, delete it.<br></p>
<h3 id="table-of-contents">Table of contents</h3>
<!-- Adjust these page numbers as necessary -->

<p>Copyright            i
Preface                ii
Table of Contents    iii
List of Tables        vi
List of Figures        v
Nomenclature        vi
Abstract            vii</p>
<p><strong>Chaper 1 Introduction...........................................................1</strong></p>
<p>1.1 A Major Section...............................................................1
1.1.1 A Major Subsection..........................................................1
1.2 Another Major Subsection......................................................1
1.3 Report Outline................................................................1</p>
<p><strong>Chapter 2 A Review of your subject and topics...................................2</strong></p>
<p>2.1 Foo...........................................................................2
2.2 Bar...........................................................................2
2.3 Chapter Summary...............................................................2</p>
<p><strong>Chapter 3 Artefact Design.......................................................3</strong></p>
<p>3.1 Introduction..................................................................3
3.2 Methodology...................................................................3
3.3 Requirements..................................................................3
3.4 Proposed Solution.............................................................3
3.5 Summary.......................................................................3</p>
<p><strong>Chapter 4 System Implementation................................................4</strong></p>
<p>4.1 Introduction.................................................................4
4.2 Foo..........................................................................4
4.3 Interesting Problems.........................................................4
4.4 Summary......................................................................4</p>
<p><strong>Chapter 5 Testing and Evaluation...............................................5</strong></p>
<p>5.1 Introduction.................................................................5
5.2 Testing Summary..............................................................5
5.3 Evaluation...................................................................5
5.3.1 Requirements Review........................................................5
5.3.2 Artefact Review............................................................5
5.4 Testing and Evaluation Summary...............................................5</p>
<p><strong>Chapter 6 Conclusion...........................................................6</strong></p>
<p>6.1 Introduction.................................................................6
6.2 Summary......................................................................6
6.3 Conclusions..................................................................6
6.3.1 Key Points.................................................................6</p>
<p><strong>Chapter 7 References...........................................................7</strong></p>
<p><strong>Appendices</strong></p>
<p>Something interesting
Something else<br></p>
<h3 id="list-of-tables">List of Tables</h3>
<p>Table 1: An interesting table</p>
<h3 id="list-of-figures">List of Figures</h3>
<!-- Adjust page numbers as necessary -->
Figure 1: An example diagram that shows four connected things        1

### Nomenclature

A number of key terms are used throughout this document and are defined here:

<!-- A nomenclature section can be useful way of defining common terms without having to include a lot of bracketed terms in your document. If you prefer to introduce terms when they are first used, remove this section -->

<h3 id="abstract">Abstract</h3>
<!-- The abstract should be the last thing you write, it is a summary of the introduction that is only a few sentences long. At most it should be a couple of paragraphs. It must be very succinct. --><br>
### Chapter 1 Introduction

This chapter introduces the overarching themes of this report and places the motivation for the work in context. Thereafter, the rationale and goals defined for the investigation of the project are discussed. followed by a summary of the overall project. Finally, an overview of the dissertation is given on a per-chapter basis.

<!-- Your words begin here at the high level, then dive into detail in sections and subsections... --><br>
#### 1.1 A Major Section

<!-- Your words go here -->

<h5 id="1-1-1-a-major-subsection">1.1.1 A Major Subsection</h5>
<!-- Your words go here -->

<h6 id="a-minor-subsection">A Minor Subsection</h6>
<!-- Your words go here-->

<p><img src="../../src/img/figure1.png" alt="Figure 1: An example diagram that shows four connected things"><br></p>
<h4 id="1-2-another-major-section">1.2 Another Major Section</h4>
<p>This section shows how the numbering works<br></p>
<h3 id="chapter-2-a-review-of-">Chapter 2 A Review of...</h3>
<p>This chapter discusses the state-of-the-art of ... considered during the analysis and design phase of this project. The investigation served x purposes: firstly, we wished to identify ... (see section 2.1); and secondly we wished to establish ... (see section 2.2). Finally, section 2.3 summarises the chapter.<br></p>
<h4 id="2-1-foo">2.1 Foo</h4>
<p>Something, something, literature review<br></p>
<h4 id="2-3-bar">2.3 Bar</h4>
<p>Another something, something literature review...<br></p>
<h4 id="2-3-chapter-summary">2.3 Chapter Summary</h4>
<p>In Chapter 1 we proposed ...</p>
<p>In this chapter the state-of-the-art was categorised into ... and ... . Observations were made on the systems reviewed (see section x), and the relevance of the state-of-the-art to ... was summarised (see section y).</p>
<p>The next chapter presents the design of ..., which is a system intended to ...<br></p>
<h3 id="chapter-3-artefact-design">Chapter 3 Artefact Design</h3>
<h4 id="3-1-introduction">3.1 Introduction</h4>
<p>In the previous chapter it was identified that altmetrics are a new approach to the field of measuring scientific impact, using an array of web-based services to discover impact. Altmetrics were found to be an alternative to traditional forms of impact measurement, such as the impact factor, improving the speed, diversity and - in some cases - accuracy of impact measurements. It was found that there is little study of how altmetrics change over time, and tools are required for this analysis.</p>
<p>In this chapter, the design of a system for visualising how altmetric data sources change over time will be discussed. The first section will describe the project&#39;s design methodology (section 3.2), and then the system&#39;s requirement&#39;s will be discussed (section 3.3). Finally, a solution is proposed in section 3.4.</p>
<p><br></p>
<h4 id="3-2-design-methodology">3.2 Design Methodology</h4>
<p>The design and development of the system was supported by the methodology described in this section. The methodology is based on an agile approach, that is similar to the Scrum approach.</p>
<p>However, initially, the project took a Waterfall approach during the research and initial design phase. This methodology takes a sequential approach where tasks are ordered and one task cannot start before another. One of the benefits of this methodology is that design must be done first, leading to greater efficiency later. It is useful in this situation, as there are few specific requirements early in the process, and research is required before design can start. Using this research, decisions about the direction and requirements for the system will be made, decisions that drive the design. The design of the system changed several times during the research phase, as more was discovered about the field of altmetrics. Research continued throughout the project, continually feeding into the design of the system.</p>
<p>After this phase, the agile approach was adopted, where a prioritised list of tasks is created based on the system requirements. These are then split into short &quot;sprint&quot; periods where focussed work on the assigned tasks was completed. During each period, planning for the task, design of the implementation, and finally the actual implementation are performed, creating a working iteration of the final product. This methodology is useful as it is good at adapting to change in the design and requirements. As change is encountered, the list of tasks can be modified, and the currently assigned task can be redesigned to fit with the change.</p>
<p>Within individual sprints of this agile phase, implementation of the final product is completed. To ensure that changes to the code base do not affect previous iterations, testing were performed. A Test Driven Development (TDD) approach was adopted, where unit tests were written before production code was written. This approach drives design before implementation by forcing consideration of the final result and of any edge cases before any implementation is attempted. It also encourages a modular design, as tests can be written for smaller parts easily and reused elsewhere. Finally, TDD encourages refactoring of poor or outdated code, as it greatly reduces the fear that rewriting the old code will introduce new bugs. The approach is increasingly becoming popular because of these attributes.</p>
<p><br></p>
<h4 id="3-3-requirements">3.3 Requirements</h4>
<p>The main purpose of the system is to provide tools for those investigating altmetrics. To achieve this, there are many requirements that are described in this section. Each requirement is numbered, for referencing later.</p>
<p>As described in section 3.2, the requirements changed as research progressed. The project is driven primarily by this research, and therefore system requirements could not be developed until after some study has been completed. It became clear that, as research developed, there is little study of how altmetrics change over time, which lead to focussing the system towards providing a tool that visualises how altmetrics change over time. Similarly, after research was conducted, several APIs were found that provide altmetrics data, thereby removing the requirement for a system to generate altmetrics data. The following requirements are taken from the latest and most up-to-date set of requirements.</p>
<h5 id="1-visualisation-of-altmetrics-data-sources">1. Visualisation of altmetrics data sources</h5>
<p>It was found in section 3.6 that more tools for analysing and visualising altmetrics data are required. In addition, it was found that validation of altmetrics is required for analysis to be accepted more widely. The system, therefore, must provide a mechanism for showing a visualisation of altmetrics data, with some validation of the data. The visualisation must allow for some comparison of article altmetrics.</p>
<p>As discussed in section 3.2, altmetrics assessment is often performed on a body of work, such as an author&#39;s career output. Therefore, the system must be able to provide a visualisation for multiple articles of interest. The system will generate a graph using altmetrics data from these selected articles. This allows the user to compare altmetrics data between these articles.</p>
<p>In addition, altmetrics researchers may only wish to focus on a subset of altmetric data sources (see section 2.6), or they may want to directly compare altmetric data sources. The system must provide a mechanism for this, by allowing the user to switch between altmetric data sources.</p>
<p>The visualisation must also show the total number of scholarly citations for the article, so that the altmetric data sources can be compared to a more traditional measure of impact. As discussed in section 3.6, citation counts are often used as a validation measure to compare against altmetrics data.</p>
<p>Finally, the visualisation must have a method for associating with the original article set, giving each article&#39;s title and final metric values. This allows the user to associate a paper with it&#39;s visualisation.</p>
<h5 id="2-visualisation-of-altmetrics-changing-over-time">2. Visualisation of altmetrics changing over time</h5>
<p>As discussed in section 3.6, there has been little or no study of the temporal aspect of altmetrics. The previous requirement discussed the need for a visualisation of altmetrics data, which can be extended to meet this requirement.</p>
<p>The system will provide a fourth axis for the graph, for the current time, and can be changed by the user. Data on the graph will be shown for the current time. For example, if this time axis shows the year 2009, then the altmetric data for 2009 will be shown on the graph. The current time will be shown on the graph, allowing the user to easily identify what the current time is.</p>
<p>The user will be able to easily change this axis, moving back and forward in time. This allows them to perform a comparison as the data changes over time. In this way, the recommendations in section 3.6 are achieved.</p>
<h5 id="3-scholarly-article-search">3. Scholarly article search</h5>
<p>Users of the system must be able to find articles that they wish to visualise altmetrics for, therefore a search for scholarly papers is required. A search form must be provided for the user, to input parameters for their query. The form must contain fields for article title, author, journal, subject area, publication date, DOI and keyword.</p>
<p>As discussed in section 2.2, altmetrics assessment is often performed on a body of work, such as an author&#39;s career output. Therefore, users must be able to identify multiple articles of interest, that altmetrics data is to be generated for.</p>
<p>The search should return articles in an identifiable manner. Articles must be uniquely addressable, so that one article can be distinguished from another. In the academic fields this is achieved using the Digital Object Identifier (DOI) System, standardised under ISO 26324. To conform with this standard, the system will return a list of DOIs that match the search parameters.</p>
<h5 id="4-altmetrics-data-collection">4. Altmetrics data collection</h5>
<p>As is evident in the previous requirements, altmetrics data is required for this system. This data could be generated by the system itself, by querying the APIs of the various services described in section 3.3 and building it&#39;s own altmetrics data. However, as described in section 3.4, there are several technical problems with collecting this data. In addition, it would take time and resources to create this data that are unavailable for this project, especially for work that is somewhat out of scope for this project. There are existing altmetrics providers that have built their own data stores which can be queried to collect this data, each of which will be assessed for suitability with this project (see requirement 10).</p>
<p>The system must pass the DOIs of the selected articles to a provider API. The system must then provide a way of accessing data from these providers for the selected articles. Finally, the system must be able to interpret their response, for use in the visualisation.</p>
<h5 id="5-storage-of-results">5. Storage of results</h5>
<p>The system must provide a way of saving visualisation results so that users can revisit later. If no storage was provided, altmetrics data would need to accessed from the provider every time the visualisation results were viewed. This creates unnecessary network traffic and would significantly slow down the application.</p>
<p>In addition, the system must provide a mechanism for accessing the resulting visualisation after generating it. This will be done using a permalink - a URL that will show the user the same visualisation, using the same altmetrics data every time the URL is visited. This allows users to demonstrate altmetrics impact to assessors without having to regenerate the data every time.</p>
<h5 id="6-easy-to-use">6. Easy to use</h5>
<p>The system must be easily understandable by users who are not familiar with technical altmetrics terms, and those outside of the technology industry. The project is aimed at users in scientific fields, who do not have a background in computer science and therefore cannot be expected to understand complex systems or obscure vocabulary.</p>
<p>As part of this requirement, the system must have good visual design. Scientific software is not known for it&#39;s striking visuals, and therefore a well designed, clean layout will attract users to the system, increasing it&#39;s popularity.</p>
<h5 id="7-open-source">7. Open source</h5>
<p>As discussed in sections 3.4 and 3.6, transparency is a founding principle of altmetrics. The altmetrics community supports the use of permissive open source licenses, as they allow users to inspect how metrics were collected and calculated. Ultimately, this transparency enhances trust in altmetrics.</p>
<p>For these reasons, source code for the system must be released under an open source license, as defined by the Open Source Initiative (OSI). The OSI has several compatible licenses listed on it&#39;s website.</p>
<h5 id="8-suitability-of-node-js-for-this-project">8. Suitability of Node.js for this project</h5>
<p>As will be discussed in section 4.4, the system will be created using the server-side Javascript platform, Node.js. The project must evaluate whether Node.js is suitable for applications of this nature. Node.js was created in 2009 by Ryan Dahl, using the Google V8 Javascript engine. It is an interesting new technology, but there is some debate about it&#39;s stability and scalability.</p>
<p>For Node.js to be considered suitable, it must provide a platform that can be quick and easily built upon to construct an application such as the one described in the requirements above. The platform must enable applications to be well structured and efficient.</p>
<h5 id="9-suitability-of-d3-js-for-this-project">9. Suitability of D3.js for this project</h5>
<p>Similar to requirement 8, D3.js will be used to provide the visualisation required for this project, and this Javascript library will be evaluated to see whether it is suitable for creating visualisations. As described in requirements 1 and 2, a complex graph will be built using a large amount of altmetrics data. If D3.js can provide a stable and efficient platform for creating such graphs, then it can be considered suitable.</p>
<h5 id="10-assessment-of-existing-altmetrics-providers">10. Assessment of existing altmetrics providers</h5>
<p>As discussed in requirement 4, altmetrics data will be sourced from an altmetrics provider. The PLOS ALM API, the ImpactStory API and the Altmetric.com API all provide access to this data, with varying levels of compatibility for this project. They will be compared to see which is the most suitable for this implementation.</p>
<p>The selected provider must include historical data, where metadata on when altmetric citations occurred. For example, the API would provide a breakdown of each data source, showing the increase in altmetric citations for each year. This breakdown must be no longer than a year, otherwise any analysis would be too general to be useful. The system requires this to be able to show the difference in altmetrics data between time periods, as discussed in requirement 2.</p>
<p>In addition, the provider must be able to provide altmetrics data for a representative sample of articles. Altmetrics data can be time-consuming and resource-heavy to generate, and therefore it can be expected that not every article ever published will be covered by the provider. However, users must be able to access data for a reasonable set of articles.</p>
<p>Finally, the provider must offer data for a useful set of altmetric data sources (see section 3.3). If a provider only tracks altmetric citations from a small group of data sources, then some diversity and context is lost from the analysis. As discussed in section 3.6, this is a core concept within in altmetrics, so if significantly lost, the provider would become unsuitable for this project.</p>
<p><br></p>
<h4 id="3-4-proposed-solution">3.4 Proposed Solution</h4>
<p>The following section describes the proposed solution to the requirements laid out in section 3.3. This solution is to create a web application called Quo that will assist altmetrics researchers in studying how altmetrics change over time. The application will consist of four parts, that are described in detail in the subsections 3.4.5 - 3.4.8.</p>
<p>A web application will be created on the Node.js platform, written in the Javascript language. This application will consist of a website that allows users to search for articles that they wish to view altmetrics data for, visualise this data, and allow them to save it in a database.</p>
<p>The application will provide a search form, with various fields for article metadata. When the search is requested, the server will access the PLOS article search API, to find matching articles. A wrapper around this API will be created as a standalone module, that will abstract the implementation details of API. The module will return a JSON response containing a list of DOIs.</p>
<p>Using this list of DOIs, a request is made to the PLOS ALM (Article Level Metrics) API, to access the altmetrics data for the selected articles. Another wrapper around this API will be created, again as a standalone module. This module encapsulates the API details, and so can be reused in other projects. The module will return a JSON object containing the altmetrics data.</p>
<p>This data is then returned to the client, where it will be used to create the visualisation. The D3.js library will be used to create a bubble chart where each article is represented by a bubble, the bubble&#39;s size corresponds to the total number of citations received, and the x- and y- axis will correspond to altmetrics data sources. A forth &quot;axis&quot; will be represented by the current year, displayed on the background of the chart, and will allow users to control moving back and forward in time. The current values of the altmetric data sources will be calculated using the current year.</p>
<p>When the data is returned to the client, it will also be saved in the application&#39;s database. A Node.js module will be used to interact with the MongoDB database. Application data will be stored in a JSON-like format and associated with a unique identifier. Users can access the visualisation and data later using this unique identifier, through the use of a permalink.</p>
<h5 id="3-4-1-web-application">3.4.1 Web Application</h5>
<p>The project will create a web application to meet the requirements described in 3.3. A web application was chosen as it provides a method for everyone to access the application, quickly, easily and without downloading any large programs.</p>
<p>As discussed in section 2.6, altmetrics are diverse and measure impact from outside science - areas that may not have access to expensive computer equipment. Therefore, a medium that can be accessed by all is suited to this project. No additional programs - other than a web browser, which often come pre-installed on many devices - are required to view a website. In addition, no restrictions are placed on the usage of the web, unlike much of the existing scholarly publishing field where paywalls regularly prevent access.</p>
<p>A website also provides a useful wrapper around the separate parts of the application, as described in sections 3.4.3 - 3.4.6. Without this wrapper, users would have to manually move data between the separate parts, leading to a much more complex and frustrating user experience.</p>
<h5 id="3-4-2-node-js">3.4.2 Node.js</h5>
<p>Node.js was chosen as the server-side framework for this project, and the logic behind this choice is explained in this subsection. Node.js is designed for server-side applications, providing methods for receiving and responding to HTTP requests. Applications for this platform are written in Javascript, taking advantage of the extremely powerful Google V8 Javascript engine that Node.js is based on.</p>
<p>The fact that applications are written in Javascript is one of Node.js&#39; main advantages, as it is the same language that is used on the client-side for web development. Developers do not lose context when switching between languages, such as with a more traditional set-up with PHP programs on the backend, and Javascript on the frontend. In the past, Javascript server-side frameworks have failed, however Node.js is built on the highly optimised V8 Javascript engine, meaning that programs can be executed much faster (&quot;JavaScript Performance Rundown&quot;, 2008).</p>
<p>As a web application is to be constructed for the application, and HTTP server is required. This can be easily achieved using Node.js, creating an application that will listen for HTTP requests and sends responses. The following code snippet is taken from the Node.js website:</p>
<pre><code class="lang-js">var http = require(&#39;http&#39;);

http.createServer(function (req, res) {
    res.writeHead(200, {&#39;Content-Type&#39;: &#39;text/plain&#39;});
    res.end(&#39;Hello World\n&#39;);
}).listen(1337, &#39;127.0.0.1&#39;);

console.log(&#39;Server running at http://127.0.0.1:1337/&#39;);</code></pre>
<p>This would, when run using the Node.js command line interface, create a server that listens on port 1337 and on the 127.0.0.1 host that responds to requests with a plain text &quot;Hello World&quot;.</p>
<p>Modules are core to the Node.js platform, allowing for quick and easy addition and use of code written by yourself or others. This even applies to core parts of Node.js - in the example above, the <code>http</code> module is used and so it has to be <code>require</code>d first. The very popular npm (Node Package Manager) application comes bundled with Node.js, which enables developers to publish modules for others to use.</p>
<p>The modular philosophy that Node.js holds is very beneficial for this project. As described above, there are several sections of the application that can be split from the main project and published as standalone modules for others to use. As discussed in section 2.6, the altmetrics community encourages transparency and reuse, principles that are reflected in the Node.js developer community. These packages can be reused by any Node.js developer easily, or perhaps by a researcher looking to study altmetrics.</p>
<p>The basic server described above only provides a low-level and overly-verbose approach, that is ill-suited for thie project. For a more powerful server, a third-party module will be used. The Express module is one of the most popular modules available on npm, currently listed as the fifth most depended upon package on npm&#39;s package registry. Express offers greater control over common web server tasks, such as routing requests, templating views and generally improving upon the built-in <code>http</code> module. Express will be used as the framework for the application, receiving requests, routing them to the correct controllers and generating responses. The following snippet is taken from the Express website: </p>
<pre><code class="lang-js">var express = require(&#39;express&#39;);
var app = express();

app.get(&#39;/&#39;, function(req, res){
    res.send(&#39;hello world&#39;);
});

app.listen(3000);</code></pre>
<p>This shows the Express equivalent to the previous snippet, however in a much cleaner manner. Requests to port 3000, on the index of the current host, will return a plain text &quot;hello world&quot;. More routes can be added by registering further callbacks on the <code>app.get</code> function.</p>
<p>In the final application, Express will provide the backbone for the server, routing requests to the correct controllers, with any attached request parameters. These controllers will then call methods within the API wrapper modules, before generating responses from templates based on data returned from the modules. </p>
<h5 id="3-4-3-grunt">3.4.3 Grunt</h5>
<p>Grunt is a Javascript task runner that provides automation for many useful functions. There are several uses for this within the project including running the Node.js server, starting the MongoDB database, and process Sass files. Grunt can be configured to run these tasks from the command line, and therefore a useful collection of administration scripts can be created. Many of these tasks are packages published on Node.js&#39; package manager npm (see section 3.4.2), in the form of Grunt plugins. These plugins are designed to work with grunt, and only need to be configured to work with the current project. This configuration can be included in the project repository, to be shared with others so that they can use the administration scripts.</p>
<p>As described in section 3.4.2, Node.js has a web server that must be started from the command line. If changes are made to the application, the server must be restarted for changes to be reflected at runtime. This can become tedious in periods of heavy development. The third-party application, nodemon is design to help with this problem. nodemon will watch application files for changes and automatically restart the server. There is a Grunt plugin (called grunt-nodemon) that will perform this function, but also allow developers to add other Grunt tasks alongside nodemon. This will be used for the project to reduce development times.</p>
<p>Similarly, the database for the application must be started at boot. This is also achieved through Grunt, through the plugin, grunt-shell. This allows Grunt to call command line shell scripts, such as the one used to start the MongoDB database used for this project (see section 3.4.8). The command <code>mongod</code> will start the database, so grunt-shell is configured to run this command when the application is started.</p>
<p>The project will use the pre-processor Sass for creating stylesheets (see section 3.4.4). These must be converted to CSS before they are served to a user. This is achieved using Grunt. A plugin is used that will process the Sass files and convert them to CSS, called grunt-contrib-sass, which needs to be configured to set where the source files are and where the destination files will be. However, this plugin will need to be run every time a change is made to the source Sass files. The grunt-watch plugin will be used to watch for changes in the Sass files and automatically run the conversion scripts.</p>
<p>Finally, styles from the Twitter Bootstrap project will be used in this application (see section 3.4.4). These files do not need to be included in the repository, as they are merely included into the main CSS file without modification. Instead, another command line tool is used to download them from the project&#39;s host. Bower is &quot;front-end&quot; package manager, created by Twitter employees, for downloading open source Javascript and CSS projects. This will be configured to download the Bootstrap files, however Bower offers no options for where the files are placed within the project. This functionality is filled by the grunt-bower-task plugin. When the Grunt &quot;build&quot; task is run, the plugin will call Bower to download the files and then move them to a configured directory.</p>
<h5 id="3-4-4-styling">3.4.4 Styling</h5>
<p>Requirement 6 states that the system must be &quot;easy-to-use&quot; and have &quot;good visual design&quot;. To help improve this, the Twitter Bootstrap project will be used to provide a framework for the visual design. The project, created in CSS, allows developers to create stylesheets quickly, by providing a library of pre-constructed components. These components can be created by adding class attributes to HTML documents. In effect, Bootstrap creates a much more appealing default stylesheet for the web. For example, the following code snippet will create a button, that is shown in Figure 3.3.</p>
<pre><code class="lang-html">&lt;button class=&quot;btn btn-primary&quot;&gt;Primary&lt;/button&gt;</code></pre>
<p><img src="../../src/img/figure3-3.png" alt="Figure 3.3: Button created using Bootstrap"></p>
<ul>
<li>Sass<ul>
<li>Bootstrap</li>
</ul>
</li>
</ul>
<h5 id="3-4-5-altmetrics-data-collection">3.4.5 Altmetrics Data Collection</h5>
<p>Requirement 4 describes the need for altmetrics data collection from an external API. As discussed in this requirement, gathering new data for the system is out of scope, as it is time- and resource-heavy, and several different altmetrics providers offer APIs. There are several options available, although not all satisfy the requirements. The following table compares the different altmetrics data APIs:</p>
<ul>
<li>Table comparing altmetrics providers<ul>
<li>Features of the APIs<ul>
<li>History</li>
</ul>
</li>
<li>How data is collected<ul>
<li>Twitter</li>
</ul>
</li>
<li>Rate limits<ul>
<li>Altmetric.com rate limits are lower - &quot;significantly higher if using an api key&quot;</li>
</ul>
</li>
<li>ImpactStory api (does it still exist?)</li>
</ul>
</li>
</ul>
<p>From the table, it is clear that for this project, the most appropriate solution is the PLOS ALM (Article Level Metrics) API. Crucially, it provides historical metadata, about when altmetric citations occurred. This is obviously important as the system must be able to show altmetrics changing over time, and that cannot be achieved without this data. The PLOS ALM API also gives a more detailed breakdown of when citation occurred. Citation numbers are given every month (or every year) for each data source, whereas Altmetric.com&#39;s API only gives aggregate numbers for all data sources at set points after publication (each day in the first week, 1 month after, 3 months after, 6 months after and 1 year after). The rate limits when compared with the Altmetric.com API are much higher, beyond the greatest expected usage and so they do not need to be considered.</p>
<p>However the PLOS ALM API has a major drawback - only articles that are published with PLOS journals are tracked by the API. Altmetric data for articles published in other journals cannot be calculated since this data is not gathered. Despite this restriction, the system will still offer a very large sample of articles to users as the PLOS library is so large. In 2013, the PLOS One journal published 31500 articles (&quot;Thanking Our Peer Reviewers&quot;, 2014).</p>
<p>The PLOS ALM API gives access to altmetrics data that PLOS collects regularly. The program that collects this data has been published under an Apache 2.0 License. Requests to the API will be made with a list of DOIs that represent the articles that the user has selected (see section 3.4.4). For this application, the option for historical metadata will be added to the request. Responses are returned in JSON format, the preferred format for this project, as XML format can be difficult to parse. An example request and response are shown below:</p>
<pre><code>http://alm.plos.org/api/v3/articles?api_key={YOUR_API_KEY}&amp;ids=10.1371/journal.pone.0035869&amp;info=history

[
    {
        &quot;doi&quot;: &quot;10.1371/journal.pone.0035869&quot;,
        &quot;title&quot;: &quot;Research Blogs and the Discussion of Scholarly Information&quot;,
        &quot;url&quot;: &quot;http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0035869&quot;,
        ...
        &quot;publication_date&quot;: &quot;2012-05-11T07:00:00Z&quot;,
        ...
        &quot;views&quot;: 21454,
        &quot;shares&quot;: 135,
        &quot;bookmarks&quot;: 135,
        &quot;citations&quot;: 9,
        &quot;sources&quot;: [
            {
                &quot;name&quot;: &quot;citeulike&quot;,
                &quot;display_name&quot;: &quot;CiteULike&quot;,
                &quot;events_url&quot;: &quot;http://www.citeulike.org/doi/10.1371/journal.pone.0035869&quot;,
                &quot;metrics&quot;: {
                    &quot;pdf&quot;: null,
                    &quot;html&quot;: null,
                    &quot;shares&quot;: 25,
                    &quot;groups&quot;: null,
                    &quot;comments&quot;: null,
                    &quot;likes&quot;: null,
                    &quot;citations&quot;: null,
                    &quot;total&quot;: 25
                },
                &quot;update_date&quot;: &quot;2014-03-05T07:55:58Z&quot;,
                ...
                &quot;by_day&quot;: [
                    {
                        &quot;year&quot;: 2012,
                        &quot;month&quot;: 5,
                        &quot;day&quot;: 12,
                        ...
                        &quot;shares&quot;: 5,
                        ...
                        &quot;total&quot;: 5
                    },
                    ...
                ],
                &quot;by_month&quot;: [
                    {
                        &quot;year&quot;: 2012,
                        &quot;month&quot;: 5,
                        ...
                        &quot;shares&quot;: 17,
                        ...
                        &quot;total&quot;: 17
                    },
                    ...
                ],
                &quot;by_year&quot;: [
                    {
                        &quot;year&quot;: 2012,
                        ...
                        &quot;shares&quot;: 22,
                        ...
                        &quot;total&quot;: 22
                    },
                    ...
                ]
            },
        ]
    }
]</code></pre>
<p>This shows the generated response for the article (with DOI 10.1371/journal.pone.0035869). Firstly, the aggregate altmetrics, organised by category are given - 21454 views, 135 shares and bookmarks and 9 citations since publication. Then an array of altmetric data sources is given, each giving the total metrics for the given source. Finally, each data source reports the number of citations each day, month and year that it changes. So in this example, the article gained 5 CiteULike citations on 12th May 2012, given in the <code>by_day</code> array of the CiteULike object. Further documentation of the API is available from the API website (&quot;Public Library of Science (PLOS)&quot;, n.d.).</p>
<p>It should also be noted that the request includes an API key, which can be obtained from PLOS ALM API website. This is used to control usage of the API, however there is no published rate limit. It is not expected that this limit will be reached, and so no mitigation is planned.</p>
<p>A wrapper will be created for around this API, encapsulating it&#39;s functionality into a single library that has a uniform interface. This abstracts implementation details of the API out of other parts of the codebase that do not need to know these details. The uniform interface will make it easier for queries to be made, as only the list of DOIs will need to be provided to create a response. Another advantage of this modular approach is that if changes are made to the API, then only the wrapper will be affected.</p>
<p>The wrapper will accept a single DOI (as a string) or a list of DOIs (as an array). Optionally, configuration can be set on the wrapper, for example, setting the option to request the historical metadata as described above. These are then validated, before the request string is built using the input DOI list. The request is sent to the API, and the response is parsed to ensure no errors have occurred. The wrapper will then return this parsed response.</p>
<p>In above sections, the ability for standalone Node.js packages to be published was described. The PLOS ALM API wrapper will be published in this manner. The package will be available on the module registry, npm, allowing third-party developers to download and use the package in their own systems, encouraging further altmetrics study. The module will be released under a MIT license, giving permission for others to not only use the package but to make changes and contribute back to the source, improving the project. This shows the great benefit of Node.js&#39; modularity and altmetrics culture of openness.</p>
<h5 id="3-4-6-scholarly-article-search">3.4.6 Scholarly Article Search</h5>
<p>Requirement 3 describes the need for a scholarly article search. The proposed solution to this problem is in two parts: the search form, and the PLOS Search API wrapper. The search form will provide the user with a mechanism for interacting with the system to give their search parameters. The search wrapper will execute the search, using these parameters, to the PLOS Search API which will find matching article&#39;s in it&#39;s archive and return a list of matching articles.</p>
<p>The application will serve the search form as a static web page, containing a form. The form is a relatively simple way for users to interact with the system to find &quot;articles of interest&quot;, or articles which they wish to receive altmetrics data for. The form will provide input fields for the following, expanded from requirement 3:</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Keyword</td>
<td>Matches all text in an article</td>
</tr>
<tr>
<td>Author</td>
<td>Matches article&#39;s author name</td>
</tr>
<tr>
<td>Journal</td>
<td>Matches article&#39;s journal name</td>
</tr>
<tr>
<td>Subject area</td>
<td>Matches an article&#39;s subject area (taken from PLOS taxonomy)</td>
</tr>
<tr>
<td>Publication date</td>
<td>Matches article&#39;s publication date</td>
</tr>
<tr>
<td>DOI</td>
<td>Matches an article&#39;s Digital Object Identifier</td>
</tr>
</tbody>
</table>
<p>Once the form is submitted, a request will be made to the application server with the attached search parameters. This request can take the form of a regular POST request, or can be captured, using Javascript, and sent using an AJAX request, meaning that the form follows the convention of progressive enhancement. The parameters are received by the server and passed to the search API wrapper.</p>
<p>The search API wrapper will perform a search for articles that match these search parameters. Unfortunately, there are very few reliable sources for searchable published scholarly material. Initially, the CrossRef API was considered as it provides search for a large number of publishers. Search parameters for all of the fields required for the form are provided by this API. However, and as discussed in section 3.4.3, only articles published by PLOS can be processed by the PLOS ALM API wrapper, and therefore the search part of the system cannot return articles published by other journals. This drawback means that the sensible choice for the search API is the PLOS Search API, as this will only search for PLOS articles, and so solves the problem of users searching for non-PLOS articles. For this reason, the PLOS Search API was chosen as the search API for use in the application.</p>
<p>The PLOS Search API allows access to PLOS&#39; internal search engine, based on the Apache Lucene project, Solr. Accepted search parameters meet those required by requirement 3. Responses are returned in JSON format and an example request and response are shown below:</p>
<pre><code>GET http://api.plos.org/search?q=&quot;altmetrics&quot;&amp;wt=json&amp;api_key={YOUR_API_KEY}

response: {
    numFound: 13,
    start: 0,
    maxScore: 1.8082654,
    docs: [
        {
            id: &quot;10.1371/journal.pone.0064841&quot;,
            journal: &quot;PLoS ONE&quot;,
            eissn: &quot;1932-6203&quot;,
            publication_date: &quot;2013-05-28T00:00:00Z&quot;,
            article_type: &quot;Research Article&quot;,
            author_display: [
                &quot;Mike Thelwall&quot;,
                &quot;Stefanie Haustein&quot;,
                &quot;Vincent Larivière&quot;,
                &quot;Cassidy R. Sugimoto&quot;
            ],
            abstract: [
                ...
            ],
            title_display: &quot;Do Altmetrics Work? Twitter and Ten Other Social Web Services&quot;,
            score: 1.8082654
        },
        ...
    ]
}</code></pre>
<p>This response shows that a simple search for the keyword &quot;altmetrics&quot; will return 13 articles, including each article&#39;s DOI. These DOIs can then be used to find their altmetrics data.</p>
<p>Again, it should be noted that the request includes an API key, which can be obtained from the PLOS Search API website. However, unlike the previous API, a rate limit is enforced. If an API key exceeds 7200 requests a day then the API key will be blocked. However, it is not expected that this limit will be reached.</p>
<p>As described in the introduction for this section, a wrapper around the API will be created. This is to abstract details of the API away from other parts of the codebase, encapsulating it&#39;s functionality into one module. This will also make querying the API easier, as a uniform interface is provided. Responses will be parsed by the wrapper, making returned data more consistent.</p>
<p>The wrapper will accept search parameters as either a string or an object. A string will indicate that a keyword search is to be performed, while an object will contain key/value pairs indicating which field is to be searched with which value. These parameters are then validated, to ensure that errors made by the user will not produce invalid responses from the API. For example, any search parameter that is not used by the PLOS Search API will raise an error, as this may return an error response from the API. The wrapper will then construct a request string using the validated parameters, and send the response to the API. The response received from the API will be parsed before it is returned to the wider system.</p>
<p>Similarly to the PLOS ALM API wrapper described in section 3.4.3, the wrapper will be published separately as a package. The module will be released under a MIT license, a open source license that satisfies requirement 7. This means that others can download the module from npm, and use within their systems without having to obtain permission. This, again, shows the great benefit of Node.js&#39; modular philosophy.</p>
<h5 id="3-4-7-visualisation">3.4.7 Visualisation</h5>
<p>Requirements 1 and 2 state the need for a visualisation of altmetrics data and how it changes over time. The solution for these requirements will be a D3.js &quot;bubble&quot; chart that will show a visualisation of multiple articles with axes for two altmetrics data sources, an axis for the number of citations and an axis for time.</p>
<p>The chart will show two altmetric data sources on the x- and y-axis, allowing the user to switch between data sources of their choice. Articles are represented by a &quot;bubble&quot; on the chart that is centred according to the values of the selected data sources. The size of the bubble represents the total number of traditional scholarly citations the article has received. An example is shown below:</p>
<p><img src="../../src/img/figure3-1.png" alt="Figure 3.1: Example bubble chart"></p>
<p>This will meet some of the requirements described in requirement 1, as it allows the user to compare multiple articles against each other. Two altmetric data sources are shown on the x- and y-axis, and the number of scholarly citations is shown in the size of the bubble. Users can see if a large number of views (as in this example) leads to a large number of citations, and thus greater impact. Requirement 1 also states that the altmetric data sources must be able to change to suit the user, and so a system will be created that will allow the user to switch the x- and y-axis between the available data sources. Finally, to meet all of requirement 1, there must be some interface for associated each bubble to the article it represents. As the chart will be built using Javascript and HTML&#39;s SVG specification, it is relatively easy to add a &quot;tooltip&quot; that will appear when the user hovers over the bubble with the mouse. This will show the article&#39;s title, and current values for the selected data sources.</p>
<p>To meet requirement 2, the chart must be able to respond to users input and change the data on the chart to represent a different time period. Initially, creating a simple line graph that showed each data source against time was considered. However some tools already exist for this purpose, and comparison between data sources is difficult - a key component in requirement 1. A graph that allows comparison of data sources, while also showing changes over time is required. This area of the design was heavily influenced by Hans Rosling&#39;s &quot;Heath &amp; Wealth of Nations&quot; presentation (&quot;Hans Rosling&#39;s 200 Countries, 200 Years, 4 Minutes&quot;, 2010). In this presentation Rosling shows the life expectancy and income of 200 countries over 200 years. By animating through each year and changing the position of the bubble based on data for that year, changes at certain periods of time become evident that would have gone unseen except under close scrutiny. It is this comparison over changes over time that is missing from other visualisation styles that were considered. The concept will be adopted for the project, by animating the bubbles to move as the time changes. In addition to this animation, the user will also be able to control the passage of time manually using the mouse.</p>
<p><img src="../../src/img/figure3-2.png" alt="Figure 3.2: Animated bubble chart"></p>
<p>Much like the wrappers described in sections 3.4.3 and 3.4.4, the visualisation code will be encapsulated into a module. A small library will be created that will create the visualisation, once constructed during the system&#39;s runtime. Prototypical inheritance will be used to structure the library, giving a object-orientated style &quot;class&quot; that has a constructor, class variables and public or private methods. The library will accept basic options in it&#39;s constructor, which will set up where in the DOM the chart is to be added, and where the data can be accessed. The library will then build the chart and append it into the DOM.</p>
<p>The library will be self-contained, following the best practice of not polluting the global namespace in the browser, although it will depend on D3.js. Further, the library will follow the asynchronous module definition (AMD) convention, allowing clients to asynchronously download the library. This is often done using the popular Require.js library.</p>
<p>D3.js is a well known Javascript library used primarily for creating charts and graphs. It was chosen over other similar libraries for this application for several reasons.</p>
<p>Other potential libraries that were considered include Google Charts, and Chart.js. However, both of these libraries are focussed on instantiating a pre-made chart - line graphs, bar charts, pie charts - with a dataset. This approach is more suited to projects with a more traditional visualisation style, where a simple chart is required, and can be quickly created without overly verbose code. D3.js takes a more flexible approach, stating on it&#39;s website &quot;D3 is not a monolithic framework that seeks to provide every conceivable feature&quot; (&quot;D3.js - Data-Driven Documents&quot;, n.d.). This is much more appropriate for this project, where a custom style of chart is created specifically for this purpose.</p>
<p>D3.js is based on manipulating Scalable Vector Graphs (SVG) elements. This relatively modern technique is based on XML, and thus does not rely on raster images, meaning that graphics can be scaled without loss of resolution. This is very powerful for usage on the web, where images can be scaled down for smaller screen devices and scaled up for larger screen devices. The World Wide Web Consortium (W3C) standardised a specification for SVG in 2011, and is now supported in a majority of browsers. The D3.js library provides a cleaner, less verbose interface to the SVG specification. This makes manipulation of SVG elements in the browser relatively simple.</p>
<p>As the library is based on transformation of DOM elements, not on an internal representation of the shapes that make the chart, it can be considered more &quot;future friendly&quot;. As the web changes, and more standards are added, tools that focus on existing standards will require less change. D3.js is able to adapt to potential additions to the web specification, for example, more advanced CSS properties or new HTML elements.</p>
<p>One of D3.js&#39; most powerful features is it&#39;s concept of data &quot;joins&quot;. This functionality allows for actions that are to be taken when new data is added to the visualisation, or existing data is removed. This is extremely powerful on the web, which is increasingly dominated by asynchronous Javascript applications that can fetch new data on the fly. While this functionality is unused for this application there is scope for future work that potentially use it, further validating the choice of D3.js for this system.</p>
<p>Finally, D3.js provides a large amount of useful documentation and example applications that make it easy to learn. As described above, the library does not provide many built-in charts, and leaves much of these decisions to the developer. Therefore, a large gallery of examples helps to inspire as well as learn from.</p>
<h5 id="3-4-8-storage">3.4.8 Storage</h5>
<p>Requirement 5 describes the need for storing altmetrics data for faster and more efficient retrieval and for creating a permalink. Data from the altmetrics data collection process will be in JSON format, and so it is sensible to also store this data in JSON format. The storage process does not require a large degree of complexity, as the data only needs to be stored against a unique key so that it can be retrieved later. A key/value pair database therefore is mostly appropriate for this use case. However, future revisions of the project may require a deeper understanding of the data stored in the database. For this reason, it may be useful to have more structure to data stored in the database.</p>
<p>Data will be stored in the database after it is returned from the altmetrics API wrapper described in section 3.4.3. The application flow starts with the user submitting their search, which will call the search wrapper, returning a list of DOIs. This list of DOIs is passed to the altmetrics API wrapper, the results of which will then be stored in the database. The database will generate a unique key for this data, which is used to create a permalink. The user is then redirected to this link, and the visualisation is generated.</p>
<p>MongoDB was chosen for the application as it satisfies these requirements. Documents in MongoDB are stored in a JSON-like format, that is associated to a unique key. This is much less complex than a relational database, where a schema would have to be constructed. There are many tools for Node.js available for use with MongoDB. The most prominent is the <code>mongodb</code> library on npm. This provides a simple driver for connecting to MonogoDB, querying and updating the store. However, this library does not offer functionality for creating structure in the database. Another potentially useful library is the popular Mongoose library, that is modelled as a Object Relation Map (ORM) for MongoDB. This would give more structure to the database, while still storing data in the JSON-like format, and will likely give the best results.</p>
<h5 id="3-4-9-source-control">3.4.9 Source Control</h5>
<p>The source code of the application will be stored in a git repository, a source control system designed to assist developers write code. Code for the project will be hosted on GitHub, a service that offers code hosting for git repositories. By combining these, the project will have powerful tools for controlling, debugging and distributing code.</p>
<p>git allows developers to track and control changes to a codebase, by &quot;committing&quot; updates regularly. This is achieved by a system of cryptographic hashes generated using the source code itself. These hashes can be used as identifiers for stages in the code which can be moved between easily. This has the added benefit of helping to debug problematic code, by identifying when an error was introduced. &quot;Branches&quot; are concept within git that enable changes to be made in a semi-temporary area where developers can experiment with the codebase without fear of permanently breaking anything. Experiments can be merged into the main branch if found to be successful.</p>
<p>GitHub is a service that can accept updates, allowing code to hosted on their servers. This also gives the benefit of creating a backup. GitHub provides a easy-to-use Graphical User Interface (GUI) to git that is helpful under certain circumstances. The service also provides an issue tracker, for saving bugs and new ideas.</p>
<p>Updates can be shared using git&#39;s protocol with others who can make further changes. This means that code published under a permissive open source license can be easily edited by others before changes are submitted back to the original author. This structure enables much faster and easier open source development, as described in requirement 7.</p>
<h5 id="3-4-10-testing">3.4.10 Testing</h5>
<p>For the application to be considered to be successful, it must contain as few bugs as possible. Section 3.2 describes the project&#39;s design methodology of Test Driven Development (TDD). For this to take place, a testing framework must be included in the project. This will provide an environment for tests to be run and tested against. For this project, two libraries will be used; Mocha for running tests; and Chai for providing assertions.</p>
<p>Mocha is a test runner for Node.js, that enables developers to create tests that will be in it&#39;s environment. If an error is thrown by the test, then Mocha will report this, either on the command line, or in a browser. The example below shows a basic Mocha test (that will pass):</p>
<pre><code class="lang-js">var expect = require(&#39;chai&#39;).expect;
describe(&#39;Array&#39;, function() {
    describe(&#39;#indexOf()&#39;, function({
        it(&#39;should return -1 when the value is not present&#39;, function() {
            expect([1,2,3].indexOf(5)).to.equal(-1);
            expect([1,2,3].indexOf(0)).to.equal(-1);
        });
    });
});</code></pre>
<p>Chai is an assertion library, again for Node.js, that provides assertions that expressions can be tested against. If the assertion fails an error will be thrown. The examples below show some of the Chai assertions:</p>
<pre><code class="lang-js">expect(foo).to.not.equal(&#39;bar&#39;);
expect({ foo: &#39;baz&#39; }).to.have.property(&#39;foo&#39;).and.not.equal(&#39;bar&#39;);
expect(&#39;test&#39;).to.be.a(&#39;string&#39;);
expect(foo).to.exist;</code></pre>
<p><br></p>
<h4 id="3-5-summary">3.5 Summary</h4>
<p>This chapter described the high-level requirements and design of a system that ... . The chapter started by describing ... . The proposed solution was then discussed in section x followed by ... in section y, etc.</p>
<p>... is covered in further detail Chapter 4 which describes the implementation of ...<br></p>
<h3 id="chapter-4-system-implementation">Chapter 4 System Implementation</h3>
<h4 id="4-1-introduction">4.1 Introduction</h4>
<p>Chapter 3 presented the design of ... . This chapter builds on that design by detailing the key aspects of the ... implementation.</p>
<p>The chapter is organised as follows. Section x provides an overview of ... . Finally, in Section y, a summary of the chapter is given.<br></p>
<h4 id="bar">Bar</h4>
<p>Something, something, implementation.</p>
<ul>
<li>Visualisation<ul>
<li>Data is sparse (lots of null values)</li>
<li>PLOS doesn&#39;t provide historical metadata for citations<ul>
<li>Only total numbers</li>
<li>Good for validation anyway</li>
</ul>
</li>
<li>D3.js<ul>
<li>Un-minified version didn&#39;t work correctly<ul>
<li>Unicode problems? Had something to do with pi (π) symbols</li>
</ul>
</li>
</ul>
</li>
<li>AlmChart library<ul>
<li>AMD</li>
</ul>
</li>
</ul>
</li>
<li>Storage<ul>
<li>MongoDB<ul>
<li>Lack of schema is good<ul>
<li>Data is sparse (lots of null values), which could be problematic with relational databases<ul>
<li>Reduced complexity is good</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Mongoose<ul>
<li>ORM for Mongo</li>
<li>Creates some structure for the data<ul>
<li>Allowing more structure to queries</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Application flow<ul>
<li>How data is moved around in the application</li>
<li>The links that they click to get to permalink</li>
<li><em>Diagram showing application flow</em></li>
<li>Differences in flow for AJAX and non-AJAX users</li>
</ul>
</li>
<li>Testing<ul>
<li>What the different describe blocks in the tests mean<br><h4 id="4-3-interesting-problems">4.3 Interesting Problems</h4>
</li>
</ul>
</li>
</ul>
<p>During the project implementation several issues were identified that merit discussion. This section addresses these topics, which are ...<br></p>
<h4 id="summary">Summary</h4>
<p>This chapter described the implementation of ..., which was based on the design in Chapter 3. The implementation was introduced in Section x, and ... . Once the general implementation details had been introduced, several implementation problems were addressed in Section y, including the detailed coverage of ...<br></p>
<h3 id="chapter-5-testing-and-evaluation">Chapter 5 Testing and Evaluation</h3>
<h4 id="introduction">Introduction</h4>
<p>Chapters 3 and 4 described the design and implementation of ..., a system that ... . In this chapter, we present a testing method and its results that show ... . The chapter is organised as follows: Section x introduces ... and describes ... . Next, Section y presents ..., etc</p>
<p>The results of the test are summarised in Section z, before the solution is evaluated in Section a.</p>
<!-- Write what you did, why you did it and how you did it here --><br>
#### 5.2 Testing summary

In total over n tests were executed. Each test was ..., and this data was then used to ... . The tests illustrate that ... . In the next section, this is evaluated and the extent to which it supports these thesis is discussed.<br>
#### 5.3 Evaluation

Chapter 1 highlighted the problem of ... . Chapter 2 reviewed the state-of-the-art in ... . Chapter 3 identified a set of technical requirements underpinning the development of ..., and the implementaton of a ... was described in Chapter 4.

The testing was described in Section x demonstrates that ... . In this section therefore, we evaluate the implementation and discuss issues in the underlying technologies that the implementation has highlighted.

##### 5.3.1 Requirements Review

This section reviews the implemented platform, referring back to the requirements to identify the extent to which each has been fulfilled, and reflecting on their relevance for future work. Each of the requirements is reintroduced and discussed in turn. 

<!-- Refer back to each specified requirement and discuss -->

<h5 id="5-3-2-artefact-review">5.3.2 Artefact Review</h5>
<p>In this section, we evaluate the implementation of ... and review the prevailing issues that were highlighted by the implementation, which were ...</p>
<ul>
<li>Use PLOS Search API<ul>
<li>Can only search for PLOS articles<ul>
<li>Large sample</li>
<li>Maybe biased?<ul>
<li>Open access</li>
<li>Free - higher metrics</li>
</ul>
</li>
<li>However because they&#39;re all open access, would be normalised/accounted for</li>
</ul>
</li>
</ul>
</li>
<li>Async<ul>
<li>Difficult</li>
<li>&quot;Pyramid of doom&quot;</li>
</ul>
</li>
<li>PLOS ALM API<ul>
<li>Returned errors when calculating large amount of data<ul>
<li>Seemed to fix by requesting specific data sources</li>
</ul>
</li>
</ul>
</li>
<li>Accessibility<br><h4 id="5-4-testing-and-evaluation-summary">5.4 Testing and Evaluation Summary</h4>
</li>
</ul>
<p>This chapter introduced ... . In Section x, a series of tests were described which demonstrated ...</p>
<p>An evaluation of ... was then presented in Section y. Section z revisited the requirements described in Chapter 3 and identified that ... . Finally in Section a, the aspects of ... were discussed.<br></p>
<h3 id="chapter-6-conclusion">Chapter 6 Conclusion</h3>
<h4 id="6-1-introduction">6.1 Introduction</h4>
<p>In this Chapter, we first summarise the work described in this report (Section x). Then we draw a number of conclusions about key parts of the work undertaken in Section y, and finally in Section z we discuss future work and how we see ... helping support projects such as this one.<br></p>
<h4 id="6-2-summary">6.2 Summary</h4>
<!-- This is a summary of each chapter intro and summary -->

<p>Chapter 1 introduced ...</p>
<p>Chapter 2 reviewed the state-of-the-art in ... . ... Was introduced and ... described. The potential for ... was highlighted.</p>
<p>Chapter 3 describes the design of ... . The separate functions of ... that support the requirements were then described in more detail, including ...</p>
<p>Chapter 4 described the implementation ...</p>
<p>Chapter 5 presented a series of test that demonstrate ...<br></p>
<h4 id="6-3-conclusions">6.3 Conclusions</h4>
<p>The aim of this project was to ... . We chose to focus on ... </p>
<p>We then designed and implemented a system that could:</p>
<ul>
<li>foo</li>
<li>bar</li>
<li>baz</li>
</ul>
<p>These combined capabilites ...</p>
<p>In Chapter 1 we state the general hypothesis that ... . We have tested this thesis by ...</p>
<h5 id="6-3-1-key-points">6.3.1 Key Points</h5>
<!-- Discuss future work as you go -->

<p><strong>First key point</strong></p>
<p><strong>Second key point</strong><br></p>
<h3 id="chapter-7-references">Chapter 7 References</h3>
<p><!-- Boakes R J, Thesis Template (delete this and replace with your own). -->
<!-- Remember: Harvard APA 6th ed. --><br></p>
<h3 id="appendices">Appendices</h3>
<p><strong>Something interesting</strong></p>
<p><strong>Something else</strong></p>

  </body>
</html>
